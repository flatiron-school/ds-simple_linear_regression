{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Simple-Linear-Regression\" data-toc-modified-id=\"Simple-Linear-Regression-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Simple Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Covariance-and-Correlation\" data-toc-modified-id=\"Covariance-and-Correlation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Covariance and Correlation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Covariance\" data-toc-modified-id=\"Covariance-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Covariance</a></span></li><li><span><a href=\"#Correlation\" data-toc-modified-id=\"Correlation-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Correlation</a></span></li></ul></li><li><span><a href=\"#Causation\" data-toc-modified-id=\"Causation-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Causation</a></span></li><li><span><a href=\"#Statistical-Learning-Theory\" data-toc-modified-id=\"Statistical-Learning-Theory-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Statistical Learning Theory</a></span></li><li><span><a href=\"#Regression-Equation\" data-toc-modified-id=\"Regression-Equation-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Regression Equation</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Interpretation</a></span></li></ul></li><li><span><a href=\"#Simple-Linear-Regression-with-statsmodels\" data-toc-modified-id=\"Simple-Linear-Regression-with-statsmodels-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Simple Linear Regression with <code>statsmodels</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Sidebar:-Using-best_line()\" data-toc-modified-id=\"Sidebar:-Using-best_line()-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Sidebar: Using <code>best_line()</code></a></span></li><li><span><a href=\"#Regression-Without-Error-in-statsmodels\" data-toc-modified-id=\"Regression-Without-Error-in-statsmodels-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Regression Without Error in <code>statsmodels</code></a></span></li><li><span><a href=\"#Regression-with-Error-in-statsmodels\" data-toc-modified-id=\"Regression-with-Error-in-statsmodels-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Regression with Error in <code>statsmodels</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitted-Model-Attributes-and-Methods\" data-toc-modified-id=\"Fitted-Model-Attributes-and-Methods-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Fitted Model Attributes and Methods</a></span></li></ul></li><li><span><a href=\"#Coefficient-of-Determination\" data-toc-modified-id=\"Coefficient-of-Determination-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Coefficient of Determination</a></span></li><li><span><a href=\"#Other-Regression-Statistics\" data-toc-modified-id=\"Other-Regression-Statistics-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Other Regression Statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Log-Scaling\" data-toc-modified-id=\"Log-Scaling-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Log Scaling</a></span></li></ul></li></ul></li><li><span><a href=\"#Level-Up:--Anscombe's-Quartet\" data-toc-modified-id=\"Level-Up:--Anscombe's-Quartet-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Level Up:  <a href=\"https://www.desmos.com/calculator/paknt6oneh\" target=\"_blank\">Anscombe's Quartet</a></a></span></li><li><span><a href=\"#Level-Up:-.add_constant()\" data-toc-modified-id=\"Level-Up:-.add_constant()-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Level Up: <code>.add_constant()</code></a></span></li><li><span><a href=\"#Level-Up:-Visualization-of-Error\" data-toc-modified-id=\"Level-Up:-Visualization-of-Error-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Level Up: Visualization of Error</a></span></li><li><span><a href=\"#Level-Up:-Adjusted-$R^2$\" data-toc-modified-id=\"Level-Up:-Adjusted-$R^2$-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Level Up: Adjusted $R^2$</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:19:51.856087Z",
     "start_time": "2021-08-16T18:19:51.851248Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from random import gauss\n",
    "from lin_reg import best_line\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn.metrics as metrics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Explain and use the concepts of covariance and correlation\n",
    "- Explain how to interpret linear regressions\n",
    "- Describe the assumptions of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "1. Linearity: relationship between target and predictors is linear\n",
    "2. Independence: errors are independent\n",
    "3. Normality: errors are normally distributed\n",
    "4. Homoskedasticity: errors are homoskedastic, means they have same variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Covariance and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The idea of _correlation_ is the simple idea that variables often change _together_. For a simple example, cities with more buses tend to have higher populations.\n",
    "\n",
    "We might observe that, as one variable X increases, so does another Y, OR that as X increases, Y decreases.\n",
    "\n",
    "The _covariance_ describes how two variables co-vary. Note the similarity in the definition to the definition of ordinary variance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For two variables $X$ and $Y$, each with $n$ values:\n",
    "\n",
    "$\\Large\\sigma_{XY} = \\frac{\\Sigma^n_{i = 1}(x_i - \\mu_x)(y_i - \\mu_y)}{n}$ <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:32:43.541804Z",
     "start_time": "2021-08-16T18:32:43.539407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = [1, 3, 5]\n",
    "Y = [2, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:33:00.123043Z",
     "start_time": "2021-08-16T18:33:00.118549Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Covariance by hand:\n",
    "((1-3) * (2-7) + (3-3) * (9-7) + (5-3) * (10-7)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:33:17.736965Z",
     "start_time": "2021-08-16T18:33:17.732723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Better yet: With NumPy:\n",
    "np.cov(X, Y, ddof=0)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:33:34.657641Z",
     "start_time": "2021-08-16T18:33:34.653134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.cov(X, Y, ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:33:55.477416Z",
     "start_time": "2021-08-16T18:33:55.473635Z"
    }
   },
   "outputs": [],
   "source": [
    "np.var(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:36:04.744848Z",
     "start_time": "2021-08-16T18:36:04.740041Z"
    }
   },
   "outputs": [],
   "source": [
    "np.var(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that the value of the covariance is very much a function of the values of X and Y, which can make interpretation difficult. What is wanted is a _standardized_ scale for covariance, hence: _correlation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pearson Correlation:<br/>$\\Large r_P = \\frac{\\Sigma^n_{i = 1}(x_i - \\mu_x)(y_i - \\mu_y)}{\\sqrt{\\Sigma^n_{i = 1}(x_i - \\mu_x)^2\\Sigma^n_{i = 1}(y_i -\\mu_y)^2}}$\n",
    "\n",
    "Note that we are simply standardizing the covariance by the standard deviations of X and Y (the $n$'s cancel!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$\\bf{Check}$:\n",
    "\n",
    "<details><summary>\n",
    "What happens if X = Y?\n",
    "</summary>\n",
    "Then numerator = denominator and the correlation = 1!\n",
    "</details>\n",
    "<br/>\n",
    "We'll always have $-1 \\leq r \\leq 1$. (This was the point of standardizing by the standard deviations of X and Y.)\n",
    "\n",
    "A correlation of -1 means that X and Y are perfectly negatively correlated, and a correlation of 1 means that X and Y are perfectly positively correlated.\n",
    "\n",
    "NumPy also has a correlation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:41:24.345008Z",
     "start_time": "2021-08-16T18:41:24.341045Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.corrcoef(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:42:46.608269Z",
     "start_time": "2021-08-16T18:42:46.603688Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "4 / np.sqrt(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:43:50.165894Z",
     "start_time": "2021-08-16T18:43:50.160314Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.corrcoef(X, Y)[0, 1] == (np.cov(X, Y, ddof=0) / (np.std(X) * np.std(Y)))[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And so does SciPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T18:44:25.552072Z",
     "start_time": "2021-08-16T18:44:25.548025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stats.pearsonr(X, Y)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Causation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_Why_ does it happen that variables correlate? It _may_ be that one is the cause of the other. A city having a high population, for example, probably does have some causal effect on the number of buses that the city has. But this _need not_ be the case, and that is why statisticians are fond of saying that 'correlation is not causation'. An alternative possibility, for example, is that high values of X and Y are _both_ caused by high values of some third factor Z. The size of children's feet, for example, is correlated with their ability to spell, but this is of course NOT because either is a cause of the other. Rather, BOTH are caused by the natural maturing and development of children. As they get older, both their feet and their spelling abilities grow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Statistical Learning Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's important at this point to understand the distinction between dependent and independent variables.\n",
    "\n",
    "Roughly, the independent variable is what can be directly manipulated and the dependent variable is what cannot be (but is nevertheless of great interest). What matters structurally is simply that we understand the dependent variable to be a _function_ of the independent variable(s).\n",
    "\n",
    "This is the proper interpretation of a statistical _model_.\n",
    "\n",
    "Simple idea: We can model correlation with a _line_. As one variable changes, so does the other.\n",
    "\n",
    "This model has two *parameters*: *slope* and *y-intercept*.\n",
    "\n",
    "Unless there's a perfectly (and suspiciously) linear relationship between our predictor(s) and our target, there will  be some sort of **error** or **loss** or **residual**. The best-fit line is constructed by minimizing the sum of the squares of these losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Regression Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The solution for a simple regression best-fit line is as follows:\n",
    "\n",
    "- slope: $\\Large m = r_P\\frac{\\sigma_y}{\\sigma_x} = \\frac{cov(X, Y)}{var(X)}$\n",
    "\n",
    "- y-intercept:  $\\Large b = \\mu_y - m\\mu_x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The output of the simple linear regression algorithm is a pair of parameters: the slope and the y-intercept of the best-fit line through the data.\n",
    "\n",
    "***I therefore have a (more or less crude) MODEL of the phenomenon in question:***\n",
    "\n",
    "Suppose I have a bunch of data about \n",
    "\n",
    "- (i) how many cigarettes people smoked in their lifetimes and \n",
    "- (ii) how many years those same people lived. \n",
    "\n",
    "If I set my independent variable (\"x\") to be the number of cigarettes smoked and my dependent variable (\"y\") to be the number of years lived, then ***for any deceased person at all I will have a way of estimating the number of years that person lived if I know the number of cigarettes that that person smoked***. This estimate is exactly what the best-fit line gives me.\n",
    "\n",
    "Suppose the parameters of the regression come out to be $\\beta_0 = 100$ years and $\\beta_1 = -1\\times 10^{-4}$ years / cigarette ([in reality](https://www.medicalnewstoday.com/releases/9703#1) these are probably both a bit high).\n",
    "\n",
    "Then we would be modeling the lifespan of human beings according to the number of cigarettes smoked:\n",
    "\n",
    "$$lifespan = \\beta_0 + \\beta_1(Cigarettes)$$\n",
    "\n",
    "where $Y$ = the number of years (estimated) and $n$ is the number of cigarettes smoked.\n",
    "\n",
    "- If someone smoked 0 cigarettes, then we would estimate that person's lifespan as:\n",
    "\n",
    "$-1\\times 10^{-4}\\times 0 + 100 = 100$ years.\n",
    "\n",
    "- If someone smoked a pack a day for 30 years, that's 20 * 365 * 30 = 219000 cigarettes (never mind about leap years!), so we would estimate that person's lifespan as:\n",
    "\n",
    "$-1\\times 10^{-4}\\times 219000 + 100 = 78.1$ years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Simple Linear Regression with `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at how to build a simple linear regression model with `statsmodels`. The `statsmodels` package offers a highly descriptive report of the fit of a regression model. Let's generate a simple regression and then analyze the report!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First let's try data that fit a straight line perfectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T19:12:43.524912Z",
     "start_time": "2021-08-16T19:12:43.517423Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the x variable with np.arange()\n",
    "x = np.arange(20)\n",
    "\n",
    "# Create the perfect linear correlated y variable\n",
    "y = 3*x + 5\n",
    "\n",
    "# Create a Pandas dataframe for x and y\n",
    "test_df = pd.DataFrame({'x': x, 'y':y})\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T19:13:03.519973Z",
     "start_time": "2021-08-16T19:13:03.355847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot x and y\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Sidebar: Using `best_line()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T19:13:40.869785Z",
     "start_time": "2021-08-16T19:13:40.698878Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a best fitted line for the scatter plot\n",
    "best_line(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The best-fit line exists no matter what my data look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T19:14:42.821121Z",
     "start_time": "2021-08-16T19:14:42.645075Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create some random x and y that is not correlated\n",
    "X_rand = stats.uniform.rvs(size=100)\n",
    "Y_rand = stats.uniform.rvs(size=100)\n",
    "\n",
    "# Plot the fitted line for the random x and y\n",
    "best_line(X_rand, Y_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Experiment: [Playing with regression line](https://www.desmos.com/calculator/jwquvmikhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Regression Without Error in `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T19:17:07.046472Z",
     "start_time": "2021-08-16T19:17:07.026336Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the linear regression model with statsmodels\n",
    "model = sm.formula.ols(formula=\"y ~ x\", data=test_df)\n",
    "\n",
    "# Fitting the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Regression with Error in `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's add a little noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:07:17.591521Z",
     "start_time": "2021-08-16T17:07:17.580069Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create x and y varialbe that is linear correlated with some random noise\n",
    "x = np.arange(20)\n",
    "y = np.array([3*pt + 5 + gauss(mu=0, sigma=5) for pt in x])\n",
    "\n",
    "# Create a Pandas dataframe for x and y\n",
    "df2 = pd.DataFrame(columns=['x', 'y'])\n",
    "\n",
    "df2['x'] = x\n",
    "df2['y'] = y\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:07:24.543404Z",
     "start_time": "2021-08-16T17:07:24.525022Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the linear regression model with statsmodel\n",
    "model = sm.formula.ols(formula='y~x', data=df2)\n",
    "\n",
    "# Fitting the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please note the difference between `sm.OLS()` and `sm.formula.ols()`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fitted Model Attributes and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The fitted model has [many](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.RegressionResults.html) attributes and methods. I'll look at a couple here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:07:29.377042Z",
     "start_time": "2021-08-16T17:07:29.372247Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# t statistic for each coefficient\n",
    "model.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:07:29.879576Z",
     "start_time": "2021-08-16T17:07:29.874672Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# p value for each coefficient\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:07:30.416061Z",
     "start_time": "2021-08-16T17:07:30.413129Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mean squared error of the model\n",
    "model.mse_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `.summary()` method contains lots of helpful information about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:07:33.100561Z",
     "start_time": "2021-08-16T17:07:33.088432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are all these statistics!? Let's say a word about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Coefficient of Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Very often a data scientist will calculate $R^2$, the *coefficient of determination*, as a measure of how well the model fits the data.\n",
    "\n",
    "$R^2$ for a model is ultimately a _relational_ notion. It's a measure of goodness of fit _relative_ to a (bad) baseline model. This bad baseline model is simply the horizontal line $y = \\mu_Y$, for dependent variable $Y$.\n",
    "\n",
    "The actual calculation of $R^2$ is: <br/> $\\Large R^2\\equiv 1-\\frac{\\Sigma_i(y_i - \\hat{y}_i)^2}{\\Sigma_i(y_i - \\bar{y})^2}$.\n",
    "\n",
    "$R^2$ is a measure of how much variation in the dependent variable your model explains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Other Regression Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What else do we have in this report?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **F-statistic**: The F-test measures the significance of your model relative to a model in which all coefficients are 0, i.e. relative to a model that says there is no correlation whatever between the predictors and the target. <br/><br/>\n",
    "- **Log-Likelihood**: The probability in question is the probability of seeing these data points, *given* the model parameter values. The higher this is, the more our data conform to our model and so the better our fit. AIC and BIC are related to the log-likelihood; we'll talk about those later. <br/><br/>\n",
    "- **coef**: These are the betas as calculated by the least-squares regression. We also have p-values and 95%-confidence intervals. <br/><br/>\n",
    "- **Omnibus**: This is a test for error normality. The probability is the chance that the errors are normally distributed. <br/><br/>\n",
    "- **Durbin-Watson**: This is a test for autocorrelation. We'll return to this topic in a future lecture. <br/><br/>\n",
    "- **Jarque-Bera**: This is another test for error normality. <br/><br/>\n",
    "- **Cond. No.**: The condition number tests for independence of the predictors. Lower scores are better. When the predictors are *not* independent, we can run into problems of multicollinearity. For more on the condition number, see [here](https://stats.stackexchange.com/questions/168259/how-do-you-interpret-the-condition-number-of-a-correlation-matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Many good regression diagnostics are available in** [`statsmodels`](https://www.statsmodels.org/dev/examples/notebooks/generated/regression_diagnostics.html). For more on statsmodels regression statistics, see [here](https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Log Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is no assumption that the predictor and the target *themselves* be normally distributed. However, linear regression can work better if the predictor and target are normally distributed. \n",
    "\n",
    "Log-scaling can be a good tool to make right-skewed data more normal.\n",
    "\n",
    "Suppose e.g. a kde plot of my predictor $X$ looks like this:\n",
    "\n",
    "![original](images/skewplot.png)\n",
    "\n",
    "In that case, the kde plot of a log-transformed version of $X$ could look like this:\n",
    "\n",
    "![log](images/logplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up:  [Anscombe's Quartet](https://www.desmos.com/calculator/paknt6oneh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Why do we care about all these assumption checks? They let's us know if we've run a linear regression when we shouldn't have. Anscombe's Quartet demonstates this by showing four sets of data that are wildly different and problematic, but produce the same regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:10:26.488672Z",
     "start_time": "2021-08-16T17:10:24.585788Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ans = sns.load_dataset('anscombe')\n",
    "sns.scatterplot(data=ans, x='x', y='y', hue='dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: `.add_constant()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When using ```statsmodels``` package, there are two ways to build a linear regression model. We have demonstrated using the R-style formula method with ```statsmodels.formula.api``` module. \n",
    "\n",
    "Here we are introducing another method to build a linear regression model with ```statsmodels.api``` module. When using the ```sm.OLS()```, we need to manually add a column of ones to the predictors matrix by using the ```.add_constant()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:10:36.103086Z",
     "start_time": "2021-08-16T17:10:36.089107Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the perfectly collinear x and y\n",
    "X = np.arange(20)\n",
    "y = 3*x + 5\n",
    "\n",
    "# Create the linear regression model with statsmodels\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fitting the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:10:40.456944Z",
     "start_time": "2021-08-16T17:10:40.452766Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add a column of ones to the predictor matrix \n",
    "sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Does this make sense?\n",
    "\n",
    "Instead of setting up the regression y ~ $x_1$, we're setting up y ~ $x_0$ + $x_1$, where $x_0$ = 1 for all observations.\n",
    "\n",
    "- **Without** the constant, we're looking for a parameter $\\beta_1$ that minimizes the error around \n",
    "\n",
    "$$y = \\beta_1x$$ \n",
    "- **With** the constant, we're looking for two parameters $\\beta_0$ and $\\beta_1$ that minimize the error around \n",
    "\n",
    "$$y = \\beta_0x_0 + \\beta_1x_1 = \\beta_0 + \\beta_1x_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:11:45.552781Z",
     "start_time": "2021-08-16T17:11:45.538901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the regrssion model with statsmodels again\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "\n",
    "# Fitting the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Visualization of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:11:58.648511Z",
     "start_time": "2021-08-16T17:11:58.645910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adjusting X so that the intercept term of the best-fit line will be 0\n",
    "X = np.array([1.5, 3.5, 5.5])\n",
    "Y = np.array([2, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:11:59.341288Z",
     "start_time": "2021-08-16T17:11:59.338163Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the linear regression object with sklearn\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fitting the model with the data\n",
    "result = model.fit(X.reshape(-1, 1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:11:59.999088Z",
     "start_time": "2021-08-16T17:11:59.995330Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# attribute for estimated slope coefficient\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:00.642068Z",
     "start_time": "2021-08-16T17:12:00.638604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# attribute for estimated intercept coefficient\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:03.135735Z",
     "start_time": "2021-08-16T17:12:03.132800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a function that calculate the SSE\n",
    "def sse(m):\n",
    "    # sum of squared errors\n",
    "    line = m*X\n",
    "    err = sum(x**2 for x in [line - model.predict(X.reshape(-1, 1))])\n",
    "    return sum(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:03.892218Z",
     "start_time": "2021-08-16T17:12:03.755624Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Demostrate the error is minimized at the estimated slope cofficient\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ms = np.linspace(0, 5, 100)\n",
    "ys = [sse(m) for m in ms]\n",
    "\n",
    "ax.set_xlabel('Slope Estimates')\n",
    "ax.set_ylabel('Sum of Squared Errors')\n",
    "ax.plot(ms, ys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:05.808971Z",
     "start_time": "2021-08-16T17:12:05.806060Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Going 3d to plot error as a function of both m and b\n",
    "def new_sse(m, x, b, y):\n",
    "    \"\"\"\n",
    "    This function returns the sum of squared errors for\n",
    "    a target y and a linear estimate mx + b.\n",
    "    \"\"\"\n",
    "    return len(x) * metrics.mean_squared_error(y, m*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:06.303805Z",
     "start_time": "2021-08-16T17:12:06.299016Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Going back to our original example\n",
    "X_sample = np.array([1, 3, 5])\n",
    "Y_sample = np.array([2, 9, 10])\n",
    "\n",
    "# This should be our minimum error\n",
    "new_sse(2, X_sample, 1, Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:09.336117Z",
     "start_time": "2021-08-16T17:12:08.162079Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ms = np.linspace(-3, 7, 100)\n",
    "bs = np.linspace(-5, 5, 100)\n",
    "\n",
    "X_grid, Y_grid = np.meshgrid(ms, bs)\n",
    "\n",
    "Z = np.array([[new_sse(m, X_sample, b, Y_sample) for m in ms] for b in bs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:09.360519Z",
     "start_time": "2021-08-16T17:12:09.338375Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m_errs = {}\n",
    "for m in ms:\n",
    "    m_errs[m] = new_sse(m, X_sample, 1, Y_sample)\n",
    "print(min(m_errs.values()))\n",
    "for k in m_errs:\n",
    "    if m_errs[k] == min(m_errs.values()):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:10.938374Z",
     "start_time": "2021-08-16T17:12:10.917181Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b_errs = {}\n",
    "for b in bs:\n",
    "    b_errs[b] = new_sse(2, X_sample, b, Y_sample)\n",
    "print(min(b_errs.values()))\n",
    "for k in b_errs:\n",
    "    if b_errs[k] == min(b_errs.values()):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:11.850436Z",
     "start_time": "2021-08-16T17:12:11.313347Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X_grid, Y_grid, Z)\n",
    "ax.set_xlabel('slope')\n",
    "ax.set_ylabel('y-intercept')\n",
    "ax.set_zlabel('sum of squared errors')\n",
    "plt.title('Error as a function of slope and y-intercept');\n",
    "plt.savefig('images/surfacePlotSSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T17:12:12.931984Z",
     "start_time": "2021-08-16T17:12:12.039001Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X_grid, Y_grid, Z, 200)\n",
    "ax.set_xlabel('slope')\n",
    "ax.set_ylabel('y-intercept')\n",
    "ax.set_zlabel('sum of squared errors')\n",
    "plt.title('Error as a function of slope and y-intercept');\n",
    "plt.savefig('images/contourPlotSSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are some theoretical [objections](https://data.library.virginia.edu/is-r-squared-useless/) to using $R^2$ as an evaluator of a regression model.\n",
    "\n",
    "One objection is that, if we add another predictor to our model, $R^2$ can only *increase*! (It could hardly be that with more features I'd be able to account for *less* of the variation in the dependent variable than I could with the smaller set of features.)\n",
    "\n",
    "One improvement is **adjusted $R^2$**: <br/> $\\Large R^2_{adj.}\\equiv 1 - \\frac{(1 - R^2)(n - 1)}{n - m - 1}$, where:\n",
    "\n",
    "- n is the number of data points; and\n",
    "- m is the number of predictors.\n",
    "\n",
    "This can be a better indicator of the quality of a regression model. For more, see [here](https://www.statisticshowto.datasciencecentral.com/adjusted-r2/).\n",
    "\n",
    "Note that Adjusted $R^2$ *can* be negative!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
